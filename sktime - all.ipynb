{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## weekdays_datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['/Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.9/lib/python39.zip', '/Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9', '/Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/lib-dynload', '', '/Users/carolina/Desktop/Mestrado/.venv/lib/python3.9/site-packages', '/Users/carolina/Desktop/Mestrado', './MultiRocket']\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sys\n",
    "import os\n",
    "\n",
    "# Allows importing modules defined inside the project directory:\n",
    "path = os.path.abspath(os.path.curdir)\n",
    "while len(path) > 1 and not path.endswith('Mestrado'):\n",
    "    path = os.path.abspath(os.path.join(path, '..'))\n",
    "if path not in sys.path:\n",
    "    sys.path.append(path)\n",
    "sys.path.append('./MultiRocket')\n",
    "print(sys.path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('weekdays_datasets/df_timeseries.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Colunas CSV em weekdays_dataset.zip\n",
    "\n",
    "h00-h23: Faixa de popularidade (0-1) entre meia-noite e onze da noite\n",
    "\n",
    "country: 0 - Brasil, 1 - Estados Unidos\n",
    "\n",
    "city: 0 - Curitiba, 1 - Rio de Janeiro, 2 - SÃ£o Paulo, 0 - Chicago, 1 - New York, 2 - San Francisco\n",
    "\n",
    "category: 0 - bakeries, 1 - bars, 2 - coffee, 3 - dance clubs, 4 - restaurants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>h00</th>\n",
       "      <th>h01</th>\n",
       "      <th>h02</th>\n",
       "      <th>h03</th>\n",
       "      <th>h04</th>\n",
       "      <th>h05</th>\n",
       "      <th>h06</th>\n",
       "      <th>h07</th>\n",
       "      <th>h08</th>\n",
       "      <th>...</th>\n",
       "      <th>h17</th>\n",
       "      <th>h18</th>\n",
       "      <th>h19</th>\n",
       "      <th>h20</th>\n",
       "      <th>h21</th>\n",
       "      <th>h22</th>\n",
       "      <th>h23</th>\n",
       "      <th>country</th>\n",
       "      <th>city</th>\n",
       "      <th>category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.347754</td>\n",
       "      <td>0.522437</td>\n",
       "      <td>0.940441</td>\n",
       "      <td>0.823425</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.320058</td>\n",
       "      <td>0.212006</td>\n",
       "      <td>0.212006</td>\n",
       "      <td>0.212006</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.805263</td>\n",
       "      <td>0.483633</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.080787</td>\n",
       "      <td>0.303251</td>\n",
       "      <td>0.519247</td>\n",
       "      <td>...</td>\n",
       "      <td>0.986970</td>\n",
       "      <td>0.917125</td>\n",
       "      <td>0.562874</td>\n",
       "      <td>0.378466</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.060529</td>\n",
       "      <td>0.172893</td>\n",
       "      <td>...</td>\n",
       "      <td>0.878997</td>\n",
       "      <td>0.994609</td>\n",
       "      <td>0.901742</td>\n",
       "      <td>0.667729</td>\n",
       "      <td>0.387283</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12699</th>\n",
       "      <td>12699</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.430487</td>\n",
       "      <td>0.759348</td>\n",
       "      <td>0.991525</td>\n",
       "      <td>0.870099</td>\n",
       "      <td>0.588773</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12700</th>\n",
       "      <td>12700</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.192508</td>\n",
       "      <td>0.564814</td>\n",
       "      <td>0.973335</td>\n",
       "      <td>0.966669</td>\n",
       "      <td>0.548366</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12701</th>\n",
       "      <td>12701</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.571624</td>\n",
       "      <td>0.201609</td>\n",
       "      <td>0.144007</td>\n",
       "      <td>0.334674</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12702</th>\n",
       "      <td>12702</td>\n",
       "      <td>0.474252</td>\n",
       "      <td>0.256943</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.341396</td>\n",
       "      <td>0.630530</td>\n",
       "      <td>0.810973</td>\n",
       "      <td>0.971333</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.897192</td>\n",
       "      <td>0.743494</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12703</th>\n",
       "      <td>12703</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.341672</td>\n",
       "      <td>0.531967</td>\n",
       "      <td>0.812802</td>\n",
       "      <td>0.982816</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>12704 rows Ã 28 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          id       h00       h01  h02  h03  h04  h05       h06       h07  \\\n",
       "0          0  0.000000  0.000000  0.0  0.0  0.0  0.0  0.000000  0.000000   \n",
       "1          1  0.000000  0.000000  0.0  0.0  0.0  0.0  0.000000  0.000000   \n",
       "2          2  0.000000  0.000000  0.0  0.0  0.0  0.0  0.000000  0.000000   \n",
       "3          3  0.000000  0.000000  0.0  0.0  0.0  0.0  0.080787  0.303251   \n",
       "4          4  0.000000  0.000000  0.0  0.0  0.0  0.0  0.000000  0.060529   \n",
       "...      ...       ...       ...  ...  ...  ...  ...       ...       ...   \n",
       "12699  12699  0.000000  0.000000  0.0  0.0  0.0  0.0  0.000000  0.000000   \n",
       "12700  12700  0.000000  0.000000  0.0  0.0  0.0  0.0  0.000000  0.000000   \n",
       "12701  12701  0.000000  0.000000  0.0  0.0  0.0  0.0  0.000000  0.000000   \n",
       "12702  12702  0.474252  0.256943  0.0  0.0  0.0  0.0  0.000000  0.000000   \n",
       "12703  12703  0.000000  0.000000  0.0  0.0  0.0  0.0  0.000000  0.000000   \n",
       "\n",
       "            h08  ...       h17       h18       h19       h20       h21  \\\n",
       "0      0.000000  ...  0.347754  0.522437  0.940441  0.823425  0.000000   \n",
       "1      0.000000  ...  0.320058  0.212006  0.212006  0.212006  0.000000   \n",
       "2      0.000000  ...  0.805263  0.483633  0.000000  0.000000  0.000000   \n",
       "3      0.519247  ...  0.986970  0.917125  0.562874  0.378466  0.000000   \n",
       "4      0.172893  ...  0.878997  0.994609  0.901742  0.667729  0.387283   \n",
       "...         ...  ...       ...       ...       ...       ...       ...   \n",
       "12699  0.000000  ...  0.430487  0.759348  0.991525  0.870099  0.588773   \n",
       "12700  0.000000  ...  0.192508  0.564814  0.973335  0.966669  0.548366   \n",
       "12701  0.000000  ...  0.571624  0.201609  0.144007  0.334674  0.000000   \n",
       "12702  0.000000  ...  0.341396  0.630530  0.810973  0.971333  1.000000   \n",
       "12703  0.000000  ...  0.341672  0.531967  0.812802  0.982816  0.000000   \n",
       "\n",
       "            h22       h23  country  city  category  \n",
       "0      0.000000  0.000000      0.0   0.0       0.0  \n",
       "1      0.000000  0.000000      0.0   0.0       0.0  \n",
       "2      0.000000  0.000000      0.0   0.0       0.0  \n",
       "3      0.000000  0.000000      0.0   0.0       0.0  \n",
       "4      0.000000  0.000000      0.0   0.0       0.0  \n",
       "...         ...       ...      ...   ...       ...  \n",
       "12699  0.000000  0.000000      1.0   4.0       4.0  \n",
       "12700  0.000000  0.000000      1.0   4.0       4.0  \n",
       "12701  0.000000  0.000000      1.0   4.0       4.0  \n",
       "12702  0.897192  0.743494      1.0   4.0       4.0  \n",
       "12703  0.000000  0.000000      1.0   4.0       4.0  \n",
       "\n",
       "[12704 rows x 28 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(9528, 24) (3176, 24)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "df_x = df.drop(columns=['id','country', 'city', 'category'])\n",
    "df_y = df['category']\n",
    "\n",
    "X, y = np.array(df_x), np.array(df_y)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=11)\n",
    "print(X_train.shape, X_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## HIVECOTEV2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predicting...\n",
      "results...\n",
      "0.6656171284634761\n",
      "0.6632040546351051\n"
     ]
    }
   ],
   "source": [
    "from sktime.classification.hybrid import HIVECOTEV2\n",
    "from sktime.classification.sklearn import RotationForest\n",
    "\n",
    "hc2_classifier = HIVECOTEV2(\n",
    "    stc_params={\n",
    "        \"estimator\": RotationForest(n_estimators=3),\n",
    "        \"n_shapelet_samples\": 100,\n",
    "        \"max_shapelets\": 10,\n",
    "        \"batch_size\": 20,\n",
    "    },\n",
    "    drcif_params={\"n_estimators\": 2, \"n_intervals\": 2, \"att_subsample_size\": 2},\n",
    "    arsenal_params={\"num_kernels\": 50, \"n_estimators\": 3},\n",
    "    tde_params={\n",
    "        \"n_parameter_samples\": 10,\n",
    "        \"max_ensemble_size\": 3,\n",
    "        \"randomly_selected_params\": 5,\n",
    "    },\n",
    ")\n",
    "hc2_classifier.fit(X_train, y_train)\n",
    "print(\"predicting...\")\n",
    "hc2_pred = hc2_classifier.predict(X_test)\n",
    "print(\"results...\")\n",
    "print(accuracy_score(y_test, hc2_pred))\n",
    "print(f1_score(y_test, hc2_pred, average='weighted'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6653788988462582\n",
      "0.6656171284634761\n"
     ]
    }
   ],
   "source": [
    "print(precision_score(y_test, hc2_pred, average='weighted'))\n",
    "print(recall_score(y_test, hc2_pred, average='weighted'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "validating signatures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validating signatures...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.4"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hc2_pred_sig = hc2_classifier.predict(Xs)\n",
    "print(\"validating signatures...\")\n",
    "accuracy_score(ys, hc2_pred_sig)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hydra"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([9528, 1, 24])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "X_train_tensor = torch.tensor(np.expand_dims(X_train, axis=1), dtype=torch.float32)\n",
    "X_test_tensor = torch.tensor(np.expand_dims(X_test, axis=1), dtype=torch.float32)\n",
    "X_train_tensor.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3176, 1, 24])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test_tensor.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.677896725440806\n",
      "0.6756224614268075\n"
     ]
    }
   ],
   "source": [
    "from hydra import Hydra, SparseScaler\n",
    "from sklearn.linear_model import RidgeClassifierCV\n",
    "\n",
    "transform = Hydra(X_train.shape[-1])\n",
    "\n",
    "X_training_transform = transform(X_train_tensor)\n",
    "X_test_transform = transform(X_test_tensor)\n",
    "\n",
    "scaler = SparseScaler()\n",
    "\n",
    "X_training_transform = scaler.fit_transform(X_training_transform)\n",
    "X_test_transform = scaler.transform(X_test_transform)\n",
    "\n",
    "hydra_classifier = RidgeClassifierCV(alphas = np.logspace(-3, 3, 10))\n",
    "hydra_classifier.fit(X_training_transform, y_train)\n",
    "\n",
    "hydra_pred = hydra_classifier.predict(X_test_transform)\n",
    "print(accuracy_score(y_test, hydra_pred))\n",
    "print(f1_score(y_test, hydra_pred, average='weighted'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3176, 2048])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test_transform.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6854186662227635\n",
      "0.6854534005037783\n"
     ]
    }
   ],
   "source": [
    "print(precision_score(y_test, hydra_pred, average='weighted'))\n",
    "print(recall_score(y_test, hydra_pred, average='weighted'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hydra_pred_sig = hydra_classifier.predict(transform(torch.tensor(np.expand_dims(Xs, axis=1), dtype=torch.float32)))\n",
    "accuracy_score(ys, hydra_pred_sig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[MultiRocket] Creating MultiRocket with 6250 kernels\n",
      "[MultiRocket] Training with training set of (9528, 24)\n",
      "[MultiRocket] Kernels applied!, took 58.84903979500086s\n",
      "[MultiRocket] Transformed Shape (9528, 49728)\n",
      "[MultiRocket] Training\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch: 0:  81%|ââââââââ  | 30/37 [00:09<00:02,  3.27it/s]\n",
      "epoch: 1:  81%|ââââââââ  | 30/37 [00:02<00:00, 11.25it/s]\n",
      "epoch: 2:  81%|ââââââââ  | 30/37 [00:05<00:01,  5.88it/s]\n",
      "epoch: 3:  81%|ââââââââ  | 30/37 [00:01<00:00, 22.97it/s]\n",
      "epoch: 4:  81%|ââââââââ  | 30/37 [00:03<00:00,  9.86it/s]\n",
      "epoch: 5:  81%|ââââââââ  | 30/37 [00:03<00:00,  9.39it/s]\n",
      "epoch: 6:  81%|ââââââââ  | 30/37 [00:01<00:00, 20.76it/s]\n",
      "epoch: 7:  81%|ââââââââ  | 30/37 [00:02<00:00, 12.12it/s]\n",
      "epoch: 8:  81%|ââââââââ  | 30/37 [00:02<00:00, 14.17it/s]\n",
      "epoch: 9:  81%|ââââââââ  | 30/37 [00:01<00:00, 23.98it/s]\n",
      "epoch: 10:  81%|ââââââââ  | 30/37 [00:01<00:00, 23.37it/s]\n",
      "epoch: 11:  81%|ââââââââ  | 30/37 [00:01<00:00, 22.23it/s]\n",
      "epoch: 12:  81%|ââââââââ  | 30/37 [00:01<00:00, 23.38it/s]\n",
      "epoch: 13:  81%|ââââââââ  | 30/37 [00:03<00:00,  9.46it/s]\n",
      "epoch: 14:  81%|ââââââââ  | 30/37 [00:05<00:01,  5.08it/s]\n",
      "epoch: 15:  81%|ââââââââ  | 30/37 [00:03<00:00,  8.54it/s]\n",
      "epoch: 16:  81%|ââââââââ  | 30/37 [00:01<00:00, 23.22it/s]\n",
      "epoch: 17:  81%|ââââââââ  | 30/37 [00:04<00:01,  6.41it/s]\n",
      "epoch: 18:  81%|ââââââââ  | 30/37 [00:02<00:00, 12.86it/s]\n",
      "epoch: 19:  81%|ââââââââ  | 30/37 [00:01<00:00, 16.86it/s]\n",
      "epoch: 20:  81%|ââââââââ  | 30/37 [00:01<00:00, 19.74it/s]\n",
      "epoch: 21:  81%|ââââââââ  | 30/37 [00:03<00:00,  8.06it/s]\n",
      "epoch: 22:  81%|ââââââââ  | 30/37 [00:02<00:00, 14.58it/s]\n",
      "epoch: 23:  81%|ââââââââ  | 30/37 [00:05<00:01,  5.62it/s]\n",
      "epoch: 24:  81%|ââââââââ  | 30/37 [00:01<00:00, 18.23it/s]\n",
      "epoch: 25:  81%|ââââââââ  | 30/37 [00:01<00:00, 21.94it/s]\n",
      "epoch: 26:  81%|ââââââââ  | 30/37 [00:01<00:00, 24.35it/s]\n",
      "epoch: 27:  81%|ââââââââ  | 30/37 [00:01<00:00, 23.11it/s]\n",
      "epoch: 28:  81%|ââââââââ  | 30/37 [00:01<00:00, 19.80it/s]\n",
      "epoch: 29:  81%|ââââââââ  | 30/37 [00:01<00:00, 22.24it/s]\n",
      "epoch: 30:  81%|ââââââââ  | 30/37 [00:01<00:00, 23.85it/s]\n",
      "epoch: 31:  81%|ââââââââ  | 30/37 [00:01<00:00, 23.33it/s]\n",
      "epoch: 32:  81%|ââââââââ  | 30/37 [00:01<00:00, 23.74it/s]\n",
      "epoch: 33:  81%|ââââââââ  | 30/37 [00:01<00:00, 20.21it/s]\n",
      "epoch: 34:  81%|ââââââââ  | 30/37 [00:01<00:00, 23.71it/s]\n",
      "epoch: 35:  81%|ââââââââ  | 30/37 [00:01<00:00, 23.65it/s]\n",
      "epoch: 36:  81%|ââââââââ  | 30/37 [00:01<00:00, 23.92it/s]\n",
      "epoch: 37:  81%|ââââââââ  | 30/37 [00:01<00:00, 23.12it/s]\n",
      "epoch: 38:  81%|ââââââââ  | 30/37 [00:01<00:00, 20.11it/s]\n",
      "epoch: 39:  81%|ââââââââ  | 30/37 [00:01<00:00, 22.33it/s]\n",
      "epoch: 40:  81%|ââââââââ  | 30/37 [00:01<00:00, 15.14it/s]\n",
      "epoch: 41:  81%|ââââââââ  | 30/37 [00:01<00:00, 16.58it/s]\n",
      "epoch: 42:  81%|ââââââââ  | 30/37 [00:01<00:00, 15.88it/s]\n",
      "epoch: 43:  81%|ââââââââ  | 30/37 [00:01<00:00, 20.12it/s]\n",
      "epoch: 44:  81%|ââââââââ  | 30/37 [00:01<00:00, 21.88it/s]\n",
      "epoch: 45:  81%|ââââââââ  | 30/37 [00:01<00:00, 15.74it/s]\n",
      "epoch: 46:  81%|ââââââââ  | 30/37 [00:02<00:00, 14.64it/s]\n",
      "epoch: 47:  81%|ââââââââ  | 30/37 [00:01<00:00, 16.52it/s]\n",
      "epoch: 48:  81%|ââââââââ  | 30/37 [00:02<00:00, 14.81it/s]\n",
      "epoch: 49:  81%|ââââââââ  | 30/37 [00:01<00:00, 17.39it/s]\n",
      "epoch: 50:  81%|ââââââââ  | 30/37 [00:02<00:00, 13.00it/s]\n",
      "epoch: 51:  81%|ââââââââ  | 30/37 [00:01<00:00, 16.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "<Stopped at Epoch 52>\n",
      "[MultiRocket] Training done!, took 349.745s\n",
      "[MultiRocket] Predicting\n",
      "Kernels applied!, took 1.929s. Transformed shape: (3176, 49728).\n",
      "[MultiRocket] Predicting completed, took 2.435s\n",
      "0.6870277078085643\n",
      "0.687774729770496\n"
     ]
    }
   ],
   "source": [
    "from multirocket.multirocket import MultiRocket\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "encoder = LabelEncoder()\n",
    "y_train = encoder.fit_transform(y_train)\n",
    "y_test = encoder.transform(y_test)\n",
    "\n",
    "# returns ntc format, remove the last dimension\n",
    "X_train = X_train.reshape((X_train.shape[0], X_train.shape[1]))\n",
    "X_test = X_test.reshape((X_test.shape[0], X_test.shape[1]))\n",
    "\n",
    "nb_classes = len(np.unique(np.concatenate((y_train, y_test), axis=0)))\n",
    "\n",
    "mrocket_classifier = MultiRocket(\n",
    "    num_features=50000,\n",
    "    classifier=\"logistic\",\n",
    "    verbose=2,\n",
    ")\n",
    "yhat_train = mrocket_classifier.fit(\n",
    "    X_train, y_train,\n",
    "    predict_on_train=False\n",
    ")\n",
    "mrocket_pred = mrocket_classifier.predict(X_test)\n",
    "print(accuracy_score(y_test, mrocket_pred))\n",
    "print(f1_score(y_test, mrocket_pred, average='weighted'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6893011022948712\n",
      "0.6870277078085643\n"
     ]
    }
   ],
   "source": [
    "print(precision_score(y_test, mrocket_pred, average='weighted'))\n",
    "print(recall_score(y_test, mrocket_pred, average='weighted'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Distance based: classification is based on some time series specific distance measure between series"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Distance based classifiers use a distance function to measure the similarity between time series."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Rank 1 Proximity Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rank 1 Proximity Forest\n",
    "from sktime.classification.distance_based import ProximityForest\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_pf = ProximityForest(\n",
    "    n_estimators=2, max_depth=2, n_stump_evaluations=1\n",
    ") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "clf_pf.fit(X_train, y_train) \n",
    "y_pred_pf = clf_pf.predict(X_test) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(accuracy_score(y_test, y_pred_pf))\n",
    "print(f1_score(y_test, y_pred_pf, average='weighted'))\n",
    "print(precision_score(y_test, y_pred_pf, average='weighted'))\n",
    "print(recall_score(y_test, y_pred_pf, average='weighted'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Rank 2 Elastic Ensemble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from aeon.classification.distance_based import ElasticEnsemble\n",
    "\n",
    "clf_ee = ElasticEnsemble(\n",
    "    proportion_of_param_options=0.1,\n",
    "    proportion_train_for_test=0.1,\n",
    "    distance_measures = [\"dtw\",\"ddtw\"],\n",
    "    majority_vote=True,\n",
    ")\n",
    "clf_ee.fit(X_train, y_train)\n",
    "\n",
    "y_pred_ee = clf_ee.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.589735516372796"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y_test, y_pred_ee)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5885390583618273"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_score(y_test, y_pred_ee, average='weighted')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5990188071138511"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "precision_score(y_test, y_pred_ee, average='weighted')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.589735516372796"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recall_score(y_test, y_pred_ee, average='weighted')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature based: global features are extracted and passed to a standard clas- sifier in a simple pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Rank 1 FreshPrince"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sktime.classification.feature_based import FreshPRINCE\n",
    "#from sktime._contrib.vector_classifiers._rotation_forest import RotationForest\n",
    "\n",
    "clf_freshPRINCE = FreshPRINCE(\n",
    "    default_fc_parameters=\"minimal\",\n",
    "    n_estimators=5,\n",
    ")\n",
    "clf_freshPRINCE.fit(X_train, y_train)\n",
    "FreshPRINCE(...)\n",
    "y_pred_freshPRINCE = clf_freshPRINCE.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4905541561712846"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y_test, y_pred_freshPRINCE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.49030754338841764"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_score(y_test, y_pred_freshPRINCE, average='weighted')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.49140357099664395"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "precision_score(y_test, y_pred_freshPRINCE, average='weighted')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4905541561712846"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recall_score(y_test, y_pred_freshPRINCE, average='weighted')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Rank 2 TSFResh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sktime.classification.feature_based import TSFreshClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "clfTSFresh = TSFreshClassifier(\n",
    "    default_fc_parameters=\"minimal\",\n",
    "    estimator=RandomForestClassifier(n_estimators=5),\n",
    ")\n",
    "clfTSFresh.fit(X_train, y_train)\n",
    "TSFreshClassifier(...)\n",
    "y_pred_TSFresh = clfTSFresh.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.46914357682619645"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y_test, y_pred_TSFresh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4687427222431061"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_score(y_test, y_pred_TSFresh, average='weighted')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4708554199790814"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "precision_score(y_test, y_pred_TSFresh, average='weighted')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.46914357682619645"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recall_score(y_test, y_pred_TSFresh, average='weighted')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Interval based: features are derived from selected phase dependent intervals in an ensemble of pipelines"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Interval based classifiers adopt a random forest ensemble model, where each base classifier is a pipeline of transformation and a tree classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Rank 1 DrCIF"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Diverse Representation Canonical Interval Forest (DrCIF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6347607052896725"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from aeon.classification.compose import ChannelEnsembleClassifier\n",
    "from aeon.classification.interval_based import DrCIFClassifier\n",
    "\n",
    "from aeon.classification.convolution_based import RocketClassifier\n",
    "\n",
    "\n",
    "cls_DrCIF = ChannelEnsembleClassifier(\n",
    "    estimators=[\n",
    "        (\"DrCIF0\", DrCIFClassifier(n_estimators=5, n_intervals=2), [0]),\n",
    "        #(\"ROCKET3\", RocketClassifier(num_kernels=1000), [3, 4]),\n",
    "    ]\n",
    ")\n",
    "\n",
    "cls_DrCIF.fit(X_train, y_train)\n",
    "y_pred_DrCIF = cls_DrCIF.predict(X_test)\n",
    "\n",
    "accuracy_score(y_test, y_pred_DrCIF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6334609409152372"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_score(y_test, y_pred_DrCIF, average='weighted')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6366439143952461"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "precision_score(y_test, y_pred_DrCIF, average='weighted')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6347607052896725"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recall_score(y_test, y_pred_DrCIF, average='weighted')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Rank 2 rSTSF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Nestor Cabello, Elham Naghizade, Jianzhong Qi, Lars Kulik\n",
    "# Fast, accurate and explainable time series classification through randomization.\n",
    "# Data Min Know Disc (2023)\n",
    "\n",
    "from rSTSF_functions import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Parameters that r-STSF uses\n",
    "\n",
    "# Statistics or aggregation functions\n",
    "# Note: np.percentile and np.quantile are just used as identifiers for \n",
    "# count mean-crossings (cmc) and count of values above mean (cam) statistics. See function getIntervalFeature(...)\n",
    "agg_fns = [np.mean, np.std, np.polyfit, np.median, np.min, np.max, iqr, np.percentile, np.quantile]\n",
    "repr_types = [1,2,3,4] # 1: Raw series, 2: Periodogram, 3: First-order Difference, 4: Autoregressive\n",
    "d = 50 # Number of sets of candidate discriminatory interval features to compute\n",
    "r = 500 # Number of trees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_rSTSF = rstsf(agg_fns=agg_fns, repr_types=repr_types[:1], d=1, r=2)\n",
    "clf_rSTSF.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset:  PopularTimesGoogle\n",
      "run  1\n",
      "training time: 342.3428565490758\n",
      "testing time: 7.989115440985188\n",
      "accuracy:  0.6700251889168766\n",
      "run  2\n",
      "training time: 373.0023939309176\n",
      "testing time: 8.767640887992457\n",
      "accuracy:  0.6719143576826196\n",
      "run  3\n",
      "training time: 334.70174548903015\n",
      "testing time: 8.056428803014569\n",
      "accuracy:  0.6706549118387909\n",
      "run  4\n",
      "training time: 323.02789966901764\n",
      "testing time: 7.759123441996053\n",
      "accuracy:  0.6715994962216625\n",
      "run  5\n",
      "training time: 321.23077849298716\n",
      "testing time: 8.063391536008567\n",
      "accuracy:  0.6728589420654912\n",
      "run  6\n",
      "training time: 316.4782361430116\n",
      "testing time: 7.529486718005501\n",
      "accuracy:  0.6712846347607053\n",
      "run  7\n",
      "training time: 308.3886265089968\n",
      "testing time: 6.814754399936646\n",
      "accuracy:  0.672544080604534\n",
      "run  8\n",
      "training time: 280.0867270290619\n",
      "testing time: 6.571802795981057\n",
      "accuracy:  0.6712846347607053\n",
      "run  9\n",
      "training time: 277.16675790795125\n",
      "testing time: 6.764572376036085\n",
      "accuracy:  0.6706549118387909\n",
      "run  10\n",
      "training time: 287.4950323109515\n",
      "testing time: 6.755547544104047\n",
      "accuracy:  0.6731738035264484\n",
      "avg accuracy for 10 runs:  0.6715994962216625\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dset_names = [\"PopularTimesGoogle\"]\n",
    "\n",
    "nruns = 10\n",
    "\n",
    "accuracies = np.zeros((len(dset_names),nruns))\n",
    "training_times = []\n",
    "testing_times = []\n",
    "\n",
    "cont_dsets = 0\n",
    "for dset_name in dset_names:\n",
    "    print(\"Dataset: \", dset_name)\n",
    "\n",
    "    inner_training_time = []\n",
    "    inner_testing_time = []\n",
    "    \n",
    "    for nrun in range(nruns):\n",
    "        print('run ',str(nrun+1))\n",
    "        timeA = time.perf_counter()\n",
    "        \n",
    "        clf_rstsf = rstsf()\n",
    "        clf_rstsf.fit(X_train, y_train)\n",
    "\n",
    "        current_training_time = time.perf_counter()-timeA\n",
    "        inner_training_time.append(current_training_time)\n",
    "        print(f\"training time: {current_training_time}\")\n",
    "\n",
    "        timeA = time.perf_counter()\n",
    "        \n",
    "        y_pred_rSTSF = clf_rstsf.predict(X_test)\n",
    "\n",
    "\n",
    "        current_testing_time = time.perf_counter()-timeA\n",
    "        inner_testing_time.append(current_testing_time)\n",
    "        print(f\"testing time: {current_testing_time}\")\n",
    "\n",
    "        accu = np.sum(y_pred_rSTSF==y_test)/len(y_test)\n",
    "        print('accuracy: ', accu)\n",
    "        accuracies[cont_dsets,nrun] = accu\n",
    "\n",
    "    avg_accuracy_this_dataset = np.mean(accuracies[cont_dsets,:])\n",
    "    print('avg accuracy for ' + str(nruns) + ' runs: ' , avg_accuracy_this_dataset)\n",
    "    \n",
    "    training_times.append(np.mean(inner_training_time))\n",
    "    testing_times.append(np.mean(inner_testing_time))\n",
    "\n",
    "    cont_dsets+=1\n",
    "    print(\"\\n\")\n",
    "\n",
    "\n",
    "## comment/uncomment the lines below according to the number of runs\n",
    "columns = {'Dataset':dset_names,\n",
    "           'run1':accuracies[:,0],\n",
    "               'run2':accuracies[:,1],\n",
    "               'run3':accuracies[:,2],\n",
    "               'run4':accuracies[:,3],\n",
    "               'run5':accuracies[:,4],\n",
    "               'run6':accuracies[:,5],\n",
    "               'run7':accuracies[:,6],\n",
    "               'run8':accuracies[:,7],\n",
    "               'run9':accuracies[:,8],\n",
    "               'run10':accuracies[:,9],\n",
    "           'avgAccu':np.mean(accuracies,axis=1),\n",
    "           'avgTrainTime':np.array(training_times),'avgTestTime':np.array(testing_times)}\n",
    "dfResults = pd.DataFrame(columns)\n",
    "dfResults = dfResults[['Dataset',\n",
    "                       'run1',\n",
    "                           'run2',\n",
    "                           'run3',\n",
    "                           'run4',\n",
    "                           'run5',\n",
    "                           'run6',\n",
    "                           'run7',\n",
    "                           'run8',\n",
    "                           'run9',\n",
    "                           'run10',\n",
    "                       'avgAccu','avgTrainTime','avgTestTime'\n",
    "                      ]]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6731738035264484"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6731738035264484"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y_test, y_pred_rSTSF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6720210125150334"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_score(y_test, y_pred_rSTSF, average='weighted')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.673909545319221"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "precision_score(y_test, y_pred_rSTSF, average='weighted')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6731738035264484"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recall_score(y_test, y_pred_rSTSF, average='weighted')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Shapelet based: phase independent discriminatory subseries form the basis for classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Shapelets are subseries from the training data that are independent of the phase and can be used to discriminate between classes of time series based on their presence or absence."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Rank 1 Random Dilated Shapelet Transform (RDST)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6926952141057935"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from aeon.classification.shapelet_based import RDSTClassifier\n",
    "\n",
    "rdst_AEON = RDSTClassifier()\n",
    "rdst_AEON.fit(X_train, y_train)\n",
    "y_pred_rdst_AEON = rdst_AEON.predict(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6926952141057935"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y_test, y_pred_rdst_AEON)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.69105993209306"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_score(y_test, y_pred_rdst_AEON, average='weighted')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6943262284065441"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "precision_score(y_test, y_pred_rdst_AEON, average='weighted')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6926952141057935"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recall_score(y_test, y_pred_rdst_AEON, average='weighted')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Rank 2 MrSQM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Multiple Representations Sequence Miner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mrsqm import MrSQMClassifier, MrSQMTransformer\n",
    "from sklearn import metrics\n",
    "from scipy.interpolate import interp1d\n",
    "import timeit\n",
    "\n",
    "from sklearn.linear_model import RidgeClassifierCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Train\n",
    "clf_MrSQMC = MrSQMClassifier(nsax=0, nsfa=5)\n",
    "clf_MrSQMC.fit(X_train,y_train)\n",
    "\n",
    "y_pred_MrSQMC = clf_MrSQMC.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use MrSQM Transformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfm = MrSQMTransformer()\n",
    "X_train_transform = tfm.fit_transform(X_train,y_train)\n",
    "X_test_transform = tfm.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6621536523929471\n"
     ]
    }
   ],
   "source": [
    "# use ridgecv classifier\n",
    "ridge = RidgeClassifierCV(alphas = np.logspace(-3, 3, 10)).fit(X_train_transform,y_train)\n",
    "y_pred_ridgecvt = ridge.predict(X_test_transform)\n",
    "print(metrics.accuracy_score(y_test, y_pred_ridgecvt))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6621536523929471"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y_test, y_pred_ridgecvt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6593042743917886"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_score(y_test, y_pred_ridgecvt, average='weighted')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6632592820905993"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "precision_score(y_test, y_pred_ridgecvt, average='weighted')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6621536523929471"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recall_score(y_test, y_pred_ridgecvt, average='weighted')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dictionary based: histograms of counts of repeating patterns are the fea- tures for a classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Similar to shapelet based algorithms, dictionary approaches extract phase- independent subseries. However, instead of measuring the distance to a sub- series, each window is converted into a short sequence of discrete symbols, commonly known as a word."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Rank 1 Weasel-D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "from weasel.classification.dictionary_based import WEASEL_V2\n",
    "\n",
    "clf_WEASEL_V2 = WEASEL_V2(random_state=1379, n_jobs=4)\n",
    "clf_WEASEL_V2.fit(X_train,y_train)\n",
    "y_pred_WEASEL_V2 = clf_WEASEL_V2.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6914357682619647"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y_test, y_pred_WEASEL_V2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6896066643131316"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_score(y_test, y_pred_WEASEL_V2, average='weighted')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6921659392983183"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "precision_score(y_test, y_pred_WEASEL_V2, average='weighted')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6914357682619647"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recall_score(y_test, y_pred_WEASEL_V2, average='weighted')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Rank 2 Temporal Dictonary Ensemble (TDE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "combines the best improvements introduced in WEASEL, SpatialBOSS and cBOSS and also includes several novel features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sktime.classification.dictionary_based import TemporalDictionaryEnsemble\n",
    "\n",
    "clf_TDE = TemporalDictionaryEnsemble(\n",
    "    n_parameter_samples=10,\n",
    "    max_ensemble_size=3,\n",
    "    randomly_selected_params=5,\n",
    ") \n",
    "clf_TDE.fit(X_train, y_train) \n",
    "y_pred_TDE = clf_TDE.predict(X_test) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6083123425692695"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y_test, y_pred_TDE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6070893529185151"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_score(y_test, y_pred_TDE, average='weighted')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6072339870959385"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "precision_score(y_test, y_pred_TDE, average='weighted')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6083123425692695"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recall_score(y_test, y_pred_TDE, average='weighted')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convolution based: convolutions and pooling operations create the feature space for classification "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Hydra MultiRocket\n",
    "MultiRocket\n",
    "Hydra"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deep learning based: neural network based classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Deep learning has been the most active area of TSC research since the bake off in terms of the number of publications. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Rank 1 InceptionTime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "from sktime.classification.deep_learning.inceptiontime import InceptionTimeClassifier\n",
    "\n",
    "sns.set_style(\"whitegrid\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 1., 2., 3., 4.])"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-21 13:42:05.005974: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-0471e51e-4e34-4d21-a85a-9dda1a6ca298 {color: black;background-color: white;}#sk-0471e51e-4e34-4d21-a85a-9dda1a6ca298 pre{padding: 0;}#sk-0471e51e-4e34-4d21-a85a-9dda1a6ca298 div.sk-toggleable {background-color: white;}#sk-0471e51e-4e34-4d21-a85a-9dda1a6ca298 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-0471e51e-4e34-4d21-a85a-9dda1a6ca298 label.sk-toggleable__label-arrow:before {content: \"â¸\";float: left;margin-right: 0.25em;color: #696969;}#sk-0471e51e-4e34-4d21-a85a-9dda1a6ca298 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-0471e51e-4e34-4d21-a85a-9dda1a6ca298 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-0471e51e-4e34-4d21-a85a-9dda1a6ca298 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-0471e51e-4e34-4d21-a85a-9dda1a6ca298 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-0471e51e-4e34-4d21-a85a-9dda1a6ca298 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-0471e51e-4e34-4d21-a85a-9dda1a6ca298 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"â¾\";}#sk-0471e51e-4e34-4d21-a85a-9dda1a6ca298 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-0471e51e-4e34-4d21-a85a-9dda1a6ca298 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-0471e51e-4e34-4d21-a85a-9dda1a6ca298 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-0471e51e-4e34-4d21-a85a-9dda1a6ca298 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-0471e51e-4e34-4d21-a85a-9dda1a6ca298 div.sk-estimator:hover {background-color: #d4ebff;}#sk-0471e51e-4e34-4d21-a85a-9dda1a6ca298 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-0471e51e-4e34-4d21-a85a-9dda1a6ca298 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-0471e51e-4e34-4d21-a85a-9dda1a6ca298 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 2em;bottom: 0;left: 50%;}#sk-0471e51e-4e34-4d21-a85a-9dda1a6ca298 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;}#sk-0471e51e-4e34-4d21-a85a-9dda1a6ca298 div.sk-item {z-index: 1;}#sk-0471e51e-4e34-4d21-a85a-9dda1a6ca298 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;}#sk-0471e51e-4e34-4d21-a85a-9dda1a6ca298 div.sk-parallel::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 2em;bottom: 0;left: 50%;}#sk-0471e51e-4e34-4d21-a85a-9dda1a6ca298 div.sk-parallel-item {display: flex;flex-direction: column;position: relative;background-color: white;}#sk-0471e51e-4e34-4d21-a85a-9dda1a6ca298 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-0471e51e-4e34-4d21-a85a-9dda1a6ca298 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-0471e51e-4e34-4d21-a85a-9dda1a6ca298 div.sk-parallel-item:only-child::after {width: 0;}#sk-0471e51e-4e34-4d21-a85a-9dda1a6ca298 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;position: relative;}#sk-0471e51e-4e34-4d21-a85a-9dda1a6ca298 div.sk-label label {font-family: monospace;font-weight: bold;background-color: white;display: inline-block;line-height: 1.2em;}#sk-0471e51e-4e34-4d21-a85a-9dda1a6ca298 div.sk-label-container {position: relative;z-index: 2;text-align: center;}#sk-0471e51e-4e34-4d21-a85a-9dda1a6ca298 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-0471e51e-4e34-4d21-a85a-9dda1a6ca298 div.sk-text-repr-fallback {display: none;}</style><div id='sk-0471e51e-4e34-4d21-a85a-9dda1a6ca298' class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>InceptionTimeClassifier(n_epochs=10000)</pre><b>Please rerun this cell to show the HTML repr or trust the notebook.</b></div><div class=\"sk-container\" hidden><div class='sk-item'><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=UUID('c25e8f30-f6d7-4d04-ab8a-5daa668c8403') type=\"checkbox\" checked><label for=UUID('c25e8f30-f6d7-4d04-ab8a-5daa668c8403') class='sk-toggleable__label sk-toggleable__label-arrow'>InceptionTimeClassifier</label><div class=\"sk-toggleable__content\"><pre>InceptionTimeClassifier(n_epochs=10000)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "InceptionTimeClassifier(n_epochs=10000)"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "network = InceptionTimeClassifier(n_epochs=10000, verbose=False)\n",
    "network.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m50/50\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 44ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.08847607052896725"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "network.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m50/50\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 30ms/step\n"
     ]
    }
   ],
   "source": [
    "y_pred_Inception = network.predict(X_test) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.08847607052896725"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y_test, y_pred_Inception)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.08545425766145792"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_score(y_test, y_pred_Inception, average='weighted')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.3009053455187936"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "precision_score(y_test, y_pred_Inception, average='weighted')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.08847607052896725"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recall_score(y_test, y_pred_Inception, average='weighted')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Rank 2 ResNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m199/199\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "'a' cannot be empty unless no samples are taken",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[91], line 4\u001b[0m\n\u001b[1;32m      2\u001b[0m clf_resnet \u001b[38;5;241m=\u001b[39m ResNetClassifier(n_epochs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m10000\u001b[39m) \n\u001b[1;32m      3\u001b[0m clf_resnet\u001b[38;5;241m.\u001b[39mfit(X_train, y_train)\n\u001b[0;32m----> 4\u001b[0m y_pred_resnet \u001b[38;5;241m=\u001b[39m \u001b[43mclf_resnet\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_test\u001b[49m\u001b[43m)\u001b[49m \n",
      "File \u001b[0;32m~/Desktop/Mestrado/.venv/lib/python3.9/site-packages/sktime/classification/base.py:309\u001b[0m, in \u001b[0;36mBaseClassifier.predict\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    306\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_single_class_y_pred(X, method\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpredict\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    308\u001b[0m \u001b[38;5;66;03m# call internal _predict, convert output\u001b[39;00m\n\u001b[0;32m--> 309\u001b[0m y_pred_inner \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_predict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    310\u001b[0m y_pred \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_convert_output_y(y_pred_inner)\n\u001b[1;32m    311\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m y_pred\n",
      "File \u001b[0;32m~/Desktop/Mestrado/.venv/lib/python3.9/site-packages/sktime/classification/deep_learning/base.py:76\u001b[0m, in \u001b[0;36mBaseDeepClassifier._predict\u001b[0;34m(self, X, **kwargs)\u001b[0m\n\u001b[1;32m     73\u001b[0m probs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_predict_proba(X, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m     74\u001b[0m rng \u001b[38;5;241m=\u001b[39m check_random_state(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrandom_state)\n\u001b[1;32m     75\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m np\u001b[38;5;241m.\u001b[39marray(\n\u001b[0;32m---> 76\u001b[0m     [\n\u001b[1;32m     77\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclasses_[\u001b[38;5;28mint\u001b[39m(rng\u001b[38;5;241m.\u001b[39mchoice(np\u001b[38;5;241m.\u001b[39mflatnonzero(prob \u001b[38;5;241m==\u001b[39m prob\u001b[38;5;241m.\u001b[39mmax())))]\n\u001b[1;32m     78\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m prob \u001b[38;5;129;01min\u001b[39;00m probs\n\u001b[1;32m     79\u001b[0m     ]\n\u001b[1;32m     80\u001b[0m )\n",
      "File \u001b[0;32m~/Desktop/Mestrado/.venv/lib/python3.9/site-packages/sktime/classification/deep_learning/base.py:77\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     73\u001b[0m probs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_predict_proba(X, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m     74\u001b[0m rng \u001b[38;5;241m=\u001b[39m check_random_state(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrandom_state)\n\u001b[1;32m     75\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m np\u001b[38;5;241m.\u001b[39marray(\n\u001b[1;32m     76\u001b[0m     [\n\u001b[0;32m---> 77\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclasses_[\u001b[38;5;28mint\u001b[39m(\u001b[43mrng\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mchoice\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mflatnonzero\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprob\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m==\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mprob\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmax\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m)]\n\u001b[1;32m     78\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m prob \u001b[38;5;129;01min\u001b[39;00m probs\n\u001b[1;32m     79\u001b[0m     ]\n\u001b[1;32m     80\u001b[0m )\n",
      "File \u001b[0;32mmtrand.pyx:934\u001b[0m, in \u001b[0;36mnumpy.random.mtrand.RandomState.choice\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: 'a' cannot be empty unless no samples are taken"
     ]
    }
   ],
   "source": [
    "from sktime.classification.deep_learning.resnet import ResNetClassifier\n",
    "clf_resnet = ResNetClassifier(n_epochs=10000) \n",
    "clf_resnet.fit(X_train, y_train)\n",
    "y_pred_resnet = clf_resnet.predict(X_test) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_score(y_test, y_pred_resnet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f1_score(y_test, y_pred_resnet, average='weighted')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "precision_score(y_test, y_pred_resnet, average='weighted')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "recall_score(y_test, y_pred_resnet, average='weighted')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hybrid approaches combine two or more of the above approaches"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Rank 1 HIVE-COTE version 2 (HC2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Rank 2 Time Series Combination of Heterogeneous and Integrated Embeddings Forest TS-CHIEF"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "nÃ£o encontrei o cÃ³digo/biblioteca"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## genetic algorithms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.optimize import minimize\n",
    "\n",
    "N = 1\n",
    "categ = 0\n",
    "# X_ini = np.random.rand(N*24)\n",
    "X_cat, y_cat = extract_x_y(df,0,0,categ)\n",
    "X_avg = X_cat.mean(axis=0)\n",
    "X_avg = np.pad(X_avg, ((2,2)), mode='constant', constant_values=0)\n",
    "\n",
    "def fitness(X):\n",
    "    X_np = np.array(X)\n",
    "    X_sig = transform(torch.tensor(np.expand_dims(\n",
    "        X_np.reshape(N,24),\n",
    "        axis=1\n",
    "    ), dtype=torch.float32))\n",
    "\n",
    "    violated_constraints = np.maximum(0, X_np - 1.0) + np.maximum(0, 0.0 - X_np)\n",
    "    penalty = sum(violated_constraints)\n",
    "    distance = np.mean([np.min([np.linalg.norm(X_avg[x:x+24] - row) for x in range(5)]) for row in X_np.reshape(N, 24)])\n",
    "\n",
    "    y = hydra_classifier.predict(X_sig)\n",
    "    \n",
    "    return accuracy_score([categ]*N, y), - penalty, - distance\n",
    "\n",
    "# return accuracy_score([0,0,0,0,0,1,1,1,1,1,2,2,2,2,2,3,3,3,3,3,4,4,4,4,4,5,5,5,5,5], y)\n",
    "# return accuracy_score([0,1,2,3,4,5], y)\n",
    "# res = minimize(fitness, X_ini, method = 'Nelder-Mead', options={'maxiter':100, 'disp':True,'fatol':0})\n",
    "# res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.0, -0.0, 130.93682658688874)"
      ]
     },
     "execution_count": 234,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# fitness(X_ini)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/carolina/anaconda3/lib/python3.10/site-packages/pygad/pygad.py:1139: UserWarning: The 'delay_after_gen' parameter is deprecated starting from PyGAD 3.3.0. To delay or pause the evolution after each generation, assign a callback function/method to the 'on_generation' parameter to adds some time delay.\n",
      "  warnings.warn(\"The 'delay_after_gen' parameter is deprecated starting from PyGAD 3.3.0. To delay or pause the evolution after each generation, assign a callback function/method to the 'on_generation' parameter to adds some time delay.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best solution: (array([0.00263309, 0.01618933, 0.01411421, 0.01103476, 0.00979842,\n",
      "       0.0100045 , 0.01517333, 0.01234704, 0.19178997, 0.39106192,\n",
      "       0.48274228, 0.46821296, 0.43727749, 0.4649771 , 0.47091612,\n",
      "       0.47754438, 0.5420403 , 0.681255  , 0.75840609, 0.67349862,\n",
      "       0.45992342, 0.25251185, 0.21886793, 0.06653822]), array([ 0.        , -0.        , -0.01144639]), 0)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pygad\n",
    "\n",
    "num_generations = 10000\n",
    "num_parents_mating = 10\n",
    "sol_per_pop = 50\n",
    "num_genes = N*24\n",
    "\n",
    "ga_instance = pygad.GA(num_generations=num_generations,\n",
    "                       num_parents_mating=num_parents_mating,\n",
    "                       fitness_func=lambda ga, sol, i: fitness(sol),\n",
    "                       sol_per_pop=sol_per_pop,\n",
    "                       num_genes=num_genes,\n",
    "                       init_range_low=0.0,\n",
    "                       init_range_high=1.0,\n",
    "                       random_mutation_min_val=-0.1,\n",
    "                       random_mutation_max_val=0.1)\n",
    "\n",
    "ga_instance.run()\n",
    "\n",
    "print(\"Best solution:\", ga_instance.best_solution())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0.00263309, 0.01618933, 0.01411421, 0.04375813, 0.00979842,\n",
       "        0.0100045 , 0.01517333, 0.01234704, 0.19178997, 0.39106192,\n",
       "        0.43725721, 0.46821296, 0.44570172, 0.4649771 , 0.45060536,\n",
       "        0.47754438, 0.5420403 , 0.681255  , 0.75840609, 0.67349862,\n",
       "        0.45992342, 0.25792517, 0.31360897, 0.06653822]),\n",
       " array([ 1.        , -0.        , -0.11469525]),\n",
       " 1)"
      ]
     },
     "execution_count": 266,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ga_instance.best_solution()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([ 5.46944954e-01,  5.26806322e+01,  1.83465219e-01,  2.74667180e+01,\n",
       "         5.64513407e-02,  2.63797925e-02,  5.23544331e-02, -2.04524092e-02,\n",
       "         4.93594479e-02,  2.62616546e-02, -4.04692241e-02, -1.37356289e-02,\n",
       "         4.43397657e-02,  8.18210760e-02, -1.95037527e-02, -2.23579845e-02,\n",
       "         1.79466506e-02,  6.77089101e-02,  2.32786422e-02,  3.88685292e-02,\n",
       "         1.76799080e-01,  3.21938516e-01,  8.36681933e-02,  9.50888062e-02]),\n",
       " array([  1.        , -78.26386922,  -0.25194653]),\n",
       " 3)"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ga_instance.num_generations = 9000\n",
    "ga_instance.run()\n",
    "ga_instance.best_solution()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([  0.        ,  -1.41546584, -56.92611833]),\n",
       " array([  0.        ,  -0.18383346, -58.11232558]),\n",
       " array([  0.        ,  -0.18049151, -58.0794686 ]),\n",
       " array([  0.        ,  -0.16070508, -58.07467507]),\n",
       " array([  0.        , -28.07736137, -50.12604016]),\n",
       " array([  0.        ,  -1.51885073, -56.92624906]),\n",
       " array([  0.        ,  -0.12792826, -58.11232965]),\n",
       " array([ 0.00000000e+00, -2.37488626e-02, -5.81088693e+01]),\n",
       " array([  0.        ,  -1.49581996, -56.92624338]),\n",
       " array([  0.        ,  -0.15873586, -58.11241399]),\n",
       " array([  0.        ,  -0.1760071 , -58.10881733]),\n",
       " array([  0.        , -28.15941101, -50.12610195]),\n",
       " array([  0.        , -28.0683204 , -50.20920956]),\n",
       " array([  0.        ,  -1.45678592, -56.92625747]),\n",
       " array([  0.        ,  -0.07962053, -58.08449087]),\n",
       " array([  0.        , -28.08991123, -50.1261175 ]),\n",
       " array([  0.        ,  -1.47246413, -56.92630037]),\n",
       " array([  0.        , -26.60253754, -51.69826368]),\n",
       " array([  0.        ,  -0.18780773, -58.0748694 ]),\n",
       " array([  0.        , -28.09260478, -50.12605306]),\n",
       " array([  1.        , -78.26386922,  -0.25194653]),\n",
       " array([  1.        , -68.40147286,  -9.75327464]),\n",
       " array([  1.        , -43.21724487, -27.13015896]),\n",
       " array([  1.        , -67.87909309,  -9.7134333 ]),\n",
       " array([  1.        , -53.09924805, -25.19157134]),\n",
       " array([  1.        , -53.0827873 , -25.19104671]),\n",
       " array([  1.        , -78.26386922,  -0.22777821]),\n",
       " array([  1.        , -68.62589675,  -9.69090674]),\n",
       " array([  1.       , -43.2633185, -27.1296815]),\n",
       " array([  1.        , -42.08953693, -28.22413601]),\n",
       " array([  1.        , -42.08953693, -28.22283512]),\n",
       " array([  1.        , -67.84742779,  -9.78703762]),\n",
       " array([  1.        , -53.15151212, -25.19109451]),\n",
       " array([  1.        , -78.07943663,  -0.26805724]),\n",
       " array([  1.        , -68.66077771,  -9.5955779 ]),\n",
       " array([  1.        , -42.09828548, -28.22292041]),\n",
       " array([  1.        , -67.90145108,  -9.71373852]),\n",
       " array([  1.        , -51.81688416, -26.50682605]),\n",
       " array([  1.        , -78.35423365,  -0.21451663]),\n",
       " array([  1.        , -78.20827186,  -0.22885634]),\n",
       " array([  1.        , -68.48534312,  -9.69242905]),\n",
       " array([  1.        , -43.24324087, -27.12960731]),\n",
       " array([  1.        , -42.08953693, -28.22323325]),\n",
       " array([  1.        , -67.91376524,  -9.71440527]),\n",
       " array([  1.        , -53.10961698, -25.19100013]),\n",
       " array([  1.        , -78.22200749,  -0.24778495]),\n",
       " array([  1.        , -68.46298513,  -9.69150213]),\n",
       " array([  1.        , -43.35536574, -27.12950731]),\n",
       " array([  1.        , -42.11399903, -28.22279845]),\n",
       " array([  1.        , -67.90145108,  -9.71460252])]"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted(ga_instance.last_generation_fitness,key=lambda x: x[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10000"
      ]
     },
     "execution_count": 229,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ga_instance.generations_completed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = ga_instance.plot_fitness(label=['accuracy','penalty','distance'])\n",
    "fig.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ga_instance.last_generation_fitness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 750x350 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.rcParams[\"figure.figsize\"] = [7.50, 3.50]\n",
    "plt.rcParams[\"figure.autolayout\"] = True\n",
    "\n",
    "x = range(24)\n",
    "y,fit,idx = ga_instance.best_solution()\n",
    "\n",
    "plt.title(\"Line graph\")\n",
    "for y_ in np.array(y).reshape(N,24):\n",
    "    plt.plot(x, y_)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [],
   "source": [
    "ga_instance.save('ga_1sig_ng100_npm10_spp50_categ0_10000')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TRANSFORMERS\n",
    "DTW VS TRANSFORMERS TIME SERIES\n",
    "MÃTRICAS (f1-score)\n",
    "\n",
    "OVERLEAF\n",
    "\n",
    "ESTUDO (RELATÃRIO)\n",
    "- CLASSIFICADORES (NOVAS TÃCNICAS)\n",
    "- DEEP LEARNING (SUMARIZAÃÃO)\n",
    "- OUTRAS TÃCNICAS (SUMARIZAÃÃO / LEVANTAMENTO)\n",
    "- TESTES-PILOTO \n",
    "- USO DAS ASSINATURAS (parÃ¢metros dos classificadores (talvez))\n",
    "\n",
    "- aplicar em outros datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13.0"
      ]
     },
     "execution_count": 219,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#teste\n",
    "import numpy as np\n",
    "\n",
    "# Define input signal and kernel\n",
    "signal = np.array([0, 0, 1, 2, 3, 4, 5, 0, 0])\n",
    "kernel = np.array([0, 0.5, 1, 1.5, 0])\n",
    "\n",
    "# Perform 1D convolution\n",
    "result = np.correlate(signal, kernel, mode='valid')\n",
    "\n",
    "print(\"Convolution result:\", result)\n",
    "result.max()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "18.0"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#teste\n",
    "two_d = np.array([\n",
    "    [1,2],\n",
    "    [3,4]\n",
    "])\n",
    "\n",
    "np.mean([np.correlate(\n",
    "    np.array([1,2,3,4]),\n",
    "    row\n",
    ").max() for row in two_d])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ReuniÃ£o 16/02\n",
    "\n",
    "*verificar se Ã© bom ou nÃ£o o uso de algoritmos genÃ©ticos\n",
    "\n",
    "*comparar com a geraÃ§Ã£o simples de signature pela mÃ©dia do dataframe\n",
    "\n",
    "*ver os transformers\n",
    "\n",
    "*ver se tem mais classificadores interessantes\n",
    "\n",
    "*M2 do Leonardo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "df_filtrado = df[(df['country'] == 0) & (df['city'] == 0) & (df['category'] == 1)]\n",
    "df_teste = df_filtrado.drop(columns=['id','country', 'city', 'category'])\n",
    "\n",
    "column_means = np.mean(df_teste, axis=0)\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(range(1, 25), column_means)\n",
    "\n",
    "plt.xlabel('Column')\n",
    "plt.ylabel('Mean')\n",
    "plt.title('Mean of p=0 c=0 cat=0')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 348,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_avg(country, city, cat):\n",
    "    df_filtrado = df[(df['country'] == country) & (df['city'] == city) & (df['category'] == cat)]\n",
    "    df_teste = df_filtrado.drop(columns=['id','country', 'city', 'category'])\n",
    "    column_means = np.mean(df_teste, axis=0)\n",
    "    return column_means"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 349,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_new = np.array([\n",
    "    extract_avg(0,0,0),\n",
    "    extract_avg(0,0,1),\n",
    "    extract_avg(0,0,2),\n",
    "    extract_avg(0,0,3),\n",
    "    extract_avg(0,0,4)\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 353,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([5, 1, 24])"
      ]
     },
     "execution_count": 353,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test_tensor_new = torch.tensor(np.expand_dims(X_test_new, axis=1), dtype=torch.float32)\n",
    "X_test_tensor_new.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 354,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_new = [0,1,2,3,4]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## New Hydra"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 356,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8\n",
      "0.7333333333333333\n"
     ]
    }
   ],
   "source": [
    "from hydra import Hydra, SparseScaler\n",
    "from sklearn.linear_model import RidgeClassifierCV\n",
    "\n",
    "X_test_transform_new = transform(X_test_tensor_new)\n",
    "\n",
    "X_test_transform_new = scaler.transform(X_test_transform_new)\n",
    "\n",
    "hydra_pred_new = hydra_classifier.predict(X_test_transform_new)\n",
    "\n",
    "print(accuracy_score(y_test_new, hydra_pred_new))\n",
    "print(f1_score(y_test_new, hydra_pred_new, average='weighted'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sign = pd.read_csv('weekdays_datasets/df_signatures.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>h00</th>\n",
       "      <th>h01</th>\n",
       "      <th>h02</th>\n",
       "      <th>h03</th>\n",
       "      <th>h04</th>\n",
       "      <th>h05</th>\n",
       "      <th>h06</th>\n",
       "      <th>h07</th>\n",
       "      <th>h08</th>\n",
       "      <th>...</th>\n",
       "      <th>h17</th>\n",
       "      <th>h18</th>\n",
       "      <th>h19</th>\n",
       "      <th>h20</th>\n",
       "      <th>h21</th>\n",
       "      <th>h22</th>\n",
       "      <th>h23</th>\n",
       "      <th>country</th>\n",
       "      <th>city</th>\n",
       "      <th>category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000119</td>\n",
       "      <td>...</td>\n",
       "      <td>0.896498</td>\n",
       "      <td>0.808148</td>\n",
       "      <td>0.462531</td>\n",
       "      <td>0.010060</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.003126</td>\n",
       "      <td>0.031889</td>\n",
       "      <td>0.234067</td>\n",
       "      <td>...</td>\n",
       "      <td>0.677492</td>\n",
       "      <td>0.475074</td>\n",
       "      <td>0.385600</td>\n",
       "      <td>0.248011</td>\n",
       "      <td>0.017268</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000174</td>\n",
       "      <td>0.009180</td>\n",
       "      <td>0.138568</td>\n",
       "      <td>...</td>\n",
       "      <td>0.972788</td>\n",
       "      <td>0.965489</td>\n",
       "      <td>0.831592</td>\n",
       "      <td>0.573811</td>\n",
       "      <td>0.275817</td>\n",
       "      <td>0.002511</td>\n",
       "      <td>0.000106</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.001596</td>\n",
       "      <td>0.043055</td>\n",
       "      <td>0.531299</td>\n",
       "      <td>...</td>\n",
       "      <td>0.775702</td>\n",
       "      <td>0.628683</td>\n",
       "      <td>0.533388</td>\n",
       "      <td>0.353358</td>\n",
       "      <td>0.008911</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000467</td>\n",
       "      <td>0.015091</td>\n",
       "      <td>0.179335</td>\n",
       "      <td>0.768777</td>\n",
       "      <td>...</td>\n",
       "      <td>0.412289</td>\n",
       "      <td>0.603218</td>\n",
       "      <td>0.448638</td>\n",
       "      <td>0.349549</td>\n",
       "      <td>0.154791</td>\n",
       "      <td>0.030829</td>\n",
       "      <td>0.000874</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66</th>\n",
       "      <td>66</td>\n",
       "      <td>0.497889</td>\n",
       "      <td>0.302093</td>\n",
       "      <td>0.001882</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000041</td>\n",
       "      <td>0.005409</td>\n",
       "      <td>0.075049</td>\n",
       "      <td>0.140844</td>\n",
       "      <td>0.265839</td>\n",
       "      <td>0.581515</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td>67</td>\n",
       "      <td>0.804521</td>\n",
       "      <td>0.541695</td>\n",
       "      <td>0.005939</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.076270</td>\n",
       "      <td>0.183042</td>\n",
       "      <td>0.224729</td>\n",
       "      <td>0.324142</td>\n",
       "      <td>0.479679</td>\n",
       "      <td>0.725018</td>\n",
       "      <td>0.896602</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>68</td>\n",
       "      <td>0.518485</td>\n",
       "      <td>0.394968</td>\n",
       "      <td>0.019825</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.556677</td>\n",
       "      <td>0.665041</td>\n",
       "      <td>0.706486</td>\n",
       "      <td>0.850784</td>\n",
       "      <td>0.827417</td>\n",
       "      <td>0.919327</td>\n",
       "      <td>0.747429</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69</th>\n",
       "      <td>69</td>\n",
       "      <td>0.024066</td>\n",
       "      <td>0.000008</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00002</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.002157</td>\n",
       "      <td>...</td>\n",
       "      <td>0.327476</td>\n",
       "      <td>0.501589</td>\n",
       "      <td>0.829388</td>\n",
       "      <td>0.633860</td>\n",
       "      <td>0.500545</td>\n",
       "      <td>0.039253</td>\n",
       "      <td>0.019268</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>70</td>\n",
       "      <td>0.042649</td>\n",
       "      <td>0.000410</td>\n",
       "      <td>0.000041</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000055</td>\n",
       "      <td>...</td>\n",
       "      <td>0.015850</td>\n",
       "      <td>0.079399</td>\n",
       "      <td>0.402822</td>\n",
       "      <td>0.847623</td>\n",
       "      <td>0.546787</td>\n",
       "      <td>0.089079</td>\n",
       "      <td>0.064854</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>71 rows Ã 28 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    id       h00       h01       h02      h03      h04       h05       h06  \\\n",
       "0    0  0.000000  0.000000  0.000000  0.00000  0.00000  0.000000  0.000000   \n",
       "1    1  0.000000  0.000000  0.000000  0.00000  0.00000  0.000000  0.003126   \n",
       "2    2  0.000000  0.000000  0.000000  0.00000  0.00000  0.000000  0.000174   \n",
       "3    3  0.000000  0.000000  0.000000  0.00000  0.00000  0.000000  0.001596   \n",
       "4    4  0.000000  0.000000  0.000000  0.00000  0.00000  0.000467  0.015091   \n",
       "..  ..       ...       ...       ...      ...      ...       ...       ...   \n",
       "66  66  0.497889  0.302093  0.001882  0.00000  0.00000  0.000000  0.000000   \n",
       "67  67  0.804521  0.541695  0.005939  0.00000  0.00000  0.000000  0.000000   \n",
       "68  68  0.518485  0.394968  0.019825  0.00000  0.00000  0.000000  0.000000   \n",
       "69  69  0.024066  0.000008  0.000000  0.00000  0.00002  0.000000  0.000000   \n",
       "70  70  0.042649  0.000410  0.000041  0.00001  0.00000  0.000000  0.000000   \n",
       "\n",
       "         h07       h08  ...       h17       h18       h19       h20       h21  \\\n",
       "0   0.000000  0.000119  ...  0.896498  0.808148  0.462531  0.010060  0.000000   \n",
       "1   0.031889  0.234067  ...  0.677492  0.475074  0.385600  0.248011  0.017268   \n",
       "2   0.009180  0.138568  ...  0.972788  0.965489  0.831592  0.573811  0.275817   \n",
       "3   0.043055  0.531299  ...  0.775702  0.628683  0.533388  0.353358  0.008911   \n",
       "4   0.179335  0.768777  ...  0.412289  0.603218  0.448638  0.349549  0.154791   \n",
       "..       ...       ...  ...       ...       ...       ...       ...       ...   \n",
       "66  0.000000  0.000000  ...  0.000000  0.000041  0.005409  0.075049  0.140844   \n",
       "67  0.000000  0.000000  ...  0.076270  0.183042  0.224729  0.324142  0.479679   \n",
       "68  0.000000  0.000000  ...  0.556677  0.665041  0.706486  0.850784  0.827417   \n",
       "69  0.000000  0.002157  ...  0.327476  0.501589  0.829388  0.633860  0.500545   \n",
       "70  0.000000  0.000055  ...  0.015850  0.079399  0.402822  0.847623  0.546787   \n",
       "\n",
       "         h22       h23  country  city  category  \n",
       "0   0.000000  0.000000      0.0   0.0       0.0  \n",
       "1   0.000000  0.000000      0.0   0.0       0.0  \n",
       "2   0.002511  0.000106      0.0   0.0       0.0  \n",
       "3   0.000000  0.000000      0.0   0.0       0.0  \n",
       "4   0.030829  0.000874      0.0   0.0       0.0  \n",
       "..       ...       ...      ...   ...       ...  \n",
       "66  0.265839  0.581515      1.0   4.0       3.0  \n",
       "67  0.725018  0.896602      1.0   4.0       3.0  \n",
       "68  0.919327  0.747429      1.0   4.0       3.0  \n",
       "69  0.039253  0.019268      1.0   4.0       4.0  \n",
       "70  0.089079  0.064854      1.0   4.0       4.0  \n",
       "\n",
       "[71 rows x 28 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_sign"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_timeseries = pd.read_csv('weekdays_datasets/df_timeseries.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>h00</th>\n",
       "      <th>h01</th>\n",
       "      <th>h02</th>\n",
       "      <th>h03</th>\n",
       "      <th>h04</th>\n",
       "      <th>h05</th>\n",
       "      <th>h06</th>\n",
       "      <th>h07</th>\n",
       "      <th>h08</th>\n",
       "      <th>...</th>\n",
       "      <th>h17</th>\n",
       "      <th>h18</th>\n",
       "      <th>h19</th>\n",
       "      <th>h20</th>\n",
       "      <th>h21</th>\n",
       "      <th>h22</th>\n",
       "      <th>h23</th>\n",
       "      <th>country</th>\n",
       "      <th>city</th>\n",
       "      <th>category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.347754</td>\n",
       "      <td>0.522437</td>\n",
       "      <td>0.940441</td>\n",
       "      <td>0.823425</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.320058</td>\n",
       "      <td>0.212006</td>\n",
       "      <td>0.212006</td>\n",
       "      <td>0.212006</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.805263</td>\n",
       "      <td>0.483633</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.080787</td>\n",
       "      <td>0.303251</td>\n",
       "      <td>0.519247</td>\n",
       "      <td>...</td>\n",
       "      <td>0.986970</td>\n",
       "      <td>0.917125</td>\n",
       "      <td>0.562874</td>\n",
       "      <td>0.378466</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.060529</td>\n",
       "      <td>0.172893</td>\n",
       "      <td>...</td>\n",
       "      <td>0.878997</td>\n",
       "      <td>0.994609</td>\n",
       "      <td>0.901742</td>\n",
       "      <td>0.667729</td>\n",
       "      <td>0.387283</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12699</th>\n",
       "      <td>12699</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.430487</td>\n",
       "      <td>0.759348</td>\n",
       "      <td>0.991525</td>\n",
       "      <td>0.870099</td>\n",
       "      <td>0.588773</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12700</th>\n",
       "      <td>12700</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.192508</td>\n",
       "      <td>0.564814</td>\n",
       "      <td>0.973335</td>\n",
       "      <td>0.966669</td>\n",
       "      <td>0.548366</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12701</th>\n",
       "      <td>12701</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.571624</td>\n",
       "      <td>0.201609</td>\n",
       "      <td>0.144007</td>\n",
       "      <td>0.334674</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12702</th>\n",
       "      <td>12702</td>\n",
       "      <td>0.474252</td>\n",
       "      <td>0.256943</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.341396</td>\n",
       "      <td>0.630530</td>\n",
       "      <td>0.810973</td>\n",
       "      <td>0.971333</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.897192</td>\n",
       "      <td>0.743494</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12703</th>\n",
       "      <td>12703</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.341672</td>\n",
       "      <td>0.531967</td>\n",
       "      <td>0.812802</td>\n",
       "      <td>0.982816</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>12704 rows Ã 28 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          id       h00       h01  h02  h03  h04  h05       h06       h07  \\\n",
       "0          0  0.000000  0.000000  0.0  0.0  0.0  0.0  0.000000  0.000000   \n",
       "1          1  0.000000  0.000000  0.0  0.0  0.0  0.0  0.000000  0.000000   \n",
       "2          2  0.000000  0.000000  0.0  0.0  0.0  0.0  0.000000  0.000000   \n",
       "3          3  0.000000  0.000000  0.0  0.0  0.0  0.0  0.080787  0.303251   \n",
       "4          4  0.000000  0.000000  0.0  0.0  0.0  0.0  0.000000  0.060529   \n",
       "...      ...       ...       ...  ...  ...  ...  ...       ...       ...   \n",
       "12699  12699  0.000000  0.000000  0.0  0.0  0.0  0.0  0.000000  0.000000   \n",
       "12700  12700  0.000000  0.000000  0.0  0.0  0.0  0.0  0.000000  0.000000   \n",
       "12701  12701  0.000000  0.000000  0.0  0.0  0.0  0.0  0.000000  0.000000   \n",
       "12702  12702  0.474252  0.256943  0.0  0.0  0.0  0.0  0.000000  0.000000   \n",
       "12703  12703  0.000000  0.000000  0.0  0.0  0.0  0.0  0.000000  0.000000   \n",
       "\n",
       "            h08  ...       h17       h18       h19       h20       h21  \\\n",
       "0      0.000000  ...  0.347754  0.522437  0.940441  0.823425  0.000000   \n",
       "1      0.000000  ...  0.320058  0.212006  0.212006  0.212006  0.000000   \n",
       "2      0.000000  ...  0.805263  0.483633  0.000000  0.000000  0.000000   \n",
       "3      0.519247  ...  0.986970  0.917125  0.562874  0.378466  0.000000   \n",
       "4      0.172893  ...  0.878997  0.994609  0.901742  0.667729  0.387283   \n",
       "...         ...  ...       ...       ...       ...       ...       ...   \n",
       "12699  0.000000  ...  0.430487  0.759348  0.991525  0.870099  0.588773   \n",
       "12700  0.000000  ...  0.192508  0.564814  0.973335  0.966669  0.548366   \n",
       "12701  0.000000  ...  0.571624  0.201609  0.144007  0.334674  0.000000   \n",
       "12702  0.000000  ...  0.341396  0.630530  0.810973  0.971333  1.000000   \n",
       "12703  0.000000  ...  0.341672  0.531967  0.812802  0.982816  0.000000   \n",
       "\n",
       "            h22       h23  country  city  category  \n",
       "0      0.000000  0.000000      0.0   0.0       0.0  \n",
       "1      0.000000  0.000000      0.0   0.0       0.0  \n",
       "2      0.000000  0.000000      0.0   0.0       0.0  \n",
       "3      0.000000  0.000000      0.0   0.0       0.0  \n",
       "4      0.000000  0.000000      0.0   0.0       0.0  \n",
       "...         ...       ...      ...   ...       ...  \n",
       "12699  0.000000  0.000000      1.0   4.0       4.0  \n",
       "12700  0.000000  0.000000      1.0   4.0       4.0  \n",
       "12701  0.000000  0.000000      1.0   4.0       4.0  \n",
       "12702  0.897192  0.743494      1.0   4.0       4.0  \n",
       "12703  0.000000  0.000000      1.0   4.0       4.0  \n",
       "\n",
       "[12704 rows x 28 columns]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_timeseries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Novo DataFrame:\n",
      "   id  h00  h01  h02  h03  h04  h05       h06       h07       h08  ...  \\\n",
      "0   0  0.0  0.0  0.0  0.0  0.0  0.0  0.000000  0.000000  0.000000  ...   \n",
      "1   1  0.0  0.0  0.0  0.0  0.0  0.0  0.000000  0.000000  0.000000  ...   \n",
      "2   2  0.0  0.0  0.0  0.0  0.0  0.0  0.000000  0.000000  0.000000  ...   \n",
      "3   3  0.0  0.0  0.0  0.0  0.0  0.0  0.080787  0.303251  0.519247  ...   \n",
      "4   4  0.0  0.0  0.0  0.0  0.0  0.0  0.000000  0.060529  0.172893  ...   \n",
      "\n",
      "        h15       h16       h17       h18       h19       h20       h21  h22  \\\n",
      "0  0.156741  0.132883  0.347754  0.522437  0.940441  0.823425  0.000000  0.0   \n",
      "1  0.396663  0.482997  0.320058  0.212006  0.212006  0.212006  0.000000  0.0   \n",
      "2  0.854669  0.991342  0.805263  0.483633  0.000000  0.000000  0.000000  0.0   \n",
      "3  0.551867  0.728864  0.986970  0.917125  0.562874  0.378466  0.000000  0.0   \n",
      "4  0.372387  0.625273  0.878997  0.994609  0.901742  0.667729  0.387283  0.0   \n",
      "\n",
      "   h23  category  \n",
      "0  0.0         0  \n",
      "1  0.0         0  \n",
      "2  0.0         0  \n",
      "3  0.0         0  \n",
      "4  0.0         0  \n",
      "\n",
      "[5 rows x 26 columns]\n"
     ]
    }
   ],
   "source": [
    "df_timeseries['country'] = df_timeseries['country'].astype(int)\n",
    "df_timeseries['city'] = df_timeseries['city'].astype(int)\n",
    "df_timeseries['category'] = df_timeseries['category'].astype(int)\n",
    "\n",
    "# Criar a nova coluna 'target' combinando 'country', 'city' e 'category' como inteiros\n",
    "df_timeseries['category'] = (\n",
    "    df_timeseries['country'].astype(str) +\n",
    "    df_timeseries['city'].astype(str) +\n",
    "    df_timeseries['category'].astype(str)\n",
    ").astype(int)  # Convertendo a string concatenada para inteiro\n",
    "\n",
    "# Excluir as colunas originais\n",
    "df_timeseries = df_timeseries.drop(columns=['country', 'city'])\n",
    "\n",
    "# Verifique o novo DataFrame\n",
    "print(\"Novo DataFrame:\")\n",
    "print(df_timeseries.head())\n",
    "\n",
    "# Se necessÃ¡rio, salve o novo DataFrame em um arquivo CSV\n",
    "df_timeseries.to_csv('df_timeseries_targets.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>h00</th>\n",
       "      <th>h01</th>\n",
       "      <th>h02</th>\n",
       "      <th>h03</th>\n",
       "      <th>h04</th>\n",
       "      <th>h05</th>\n",
       "      <th>h06</th>\n",
       "      <th>h07</th>\n",
       "      <th>h08</th>\n",
       "      <th>...</th>\n",
       "      <th>h15</th>\n",
       "      <th>h16</th>\n",
       "      <th>h17</th>\n",
       "      <th>h18</th>\n",
       "      <th>h19</th>\n",
       "      <th>h20</th>\n",
       "      <th>h21</th>\n",
       "      <th>h22</th>\n",
       "      <th>h23</th>\n",
       "      <th>category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.156741</td>\n",
       "      <td>0.132883</td>\n",
       "      <td>0.347754</td>\n",
       "      <td>0.522437</td>\n",
       "      <td>0.940441</td>\n",
       "      <td>0.823425</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.396663</td>\n",
       "      <td>0.482997</td>\n",
       "      <td>0.320058</td>\n",
       "      <td>0.212006</td>\n",
       "      <td>0.212006</td>\n",
       "      <td>0.212006</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.854669</td>\n",
       "      <td>0.991342</td>\n",
       "      <td>0.805263</td>\n",
       "      <td>0.483633</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.080787</td>\n",
       "      <td>0.303251</td>\n",
       "      <td>0.519247</td>\n",
       "      <td>...</td>\n",
       "      <td>0.551867</td>\n",
       "      <td>0.728864</td>\n",
       "      <td>0.986970</td>\n",
       "      <td>0.917125</td>\n",
       "      <td>0.562874</td>\n",
       "      <td>0.378466</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.060529</td>\n",
       "      <td>0.172893</td>\n",
       "      <td>...</td>\n",
       "      <td>0.372387</td>\n",
       "      <td>0.625273</td>\n",
       "      <td>0.878997</td>\n",
       "      <td>0.994609</td>\n",
       "      <td>0.901742</td>\n",
       "      <td>0.667729</td>\n",
       "      <td>0.387283</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12699</th>\n",
       "      <td>12699</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.345968</td>\n",
       "      <td>0.228686</td>\n",
       "      <td>0.430487</td>\n",
       "      <td>0.759348</td>\n",
       "      <td>0.991525</td>\n",
       "      <td>0.870099</td>\n",
       "      <td>0.588773</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>144</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12700</th>\n",
       "      <td>12700</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.192508</td>\n",
       "      <td>0.564814</td>\n",
       "      <td>0.973335</td>\n",
       "      <td>0.966669</td>\n",
       "      <td>0.548366</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>144</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12701</th>\n",
       "      <td>12701</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.381766</td>\n",
       "      <td>0.381766</td>\n",
       "      <td>0.571624</td>\n",
       "      <td>0.201609</td>\n",
       "      <td>0.144007</td>\n",
       "      <td>0.334674</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>144</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12702</th>\n",
       "      <td>12702</td>\n",
       "      <td>0.474252</td>\n",
       "      <td>0.256943</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.081856</td>\n",
       "      <td>0.174295</td>\n",
       "      <td>0.341396</td>\n",
       "      <td>0.630530</td>\n",
       "      <td>0.810973</td>\n",
       "      <td>0.971333</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.897192</td>\n",
       "      <td>0.743494</td>\n",
       "      <td>144</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12703</th>\n",
       "      <td>12703</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.252949</td>\n",
       "      <td>0.277011</td>\n",
       "      <td>0.341672</td>\n",
       "      <td>0.531967</td>\n",
       "      <td>0.812802</td>\n",
       "      <td>0.982816</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>144</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>12704 rows Ã 26 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          id       h00       h01  h02  h03  h04  h05       h06       h07  \\\n",
       "0          0  0.000000  0.000000  0.0  0.0  0.0  0.0  0.000000  0.000000   \n",
       "1          1  0.000000  0.000000  0.0  0.0  0.0  0.0  0.000000  0.000000   \n",
       "2          2  0.000000  0.000000  0.0  0.0  0.0  0.0  0.000000  0.000000   \n",
       "3          3  0.000000  0.000000  0.0  0.0  0.0  0.0  0.080787  0.303251   \n",
       "4          4  0.000000  0.000000  0.0  0.0  0.0  0.0  0.000000  0.060529   \n",
       "...      ...       ...       ...  ...  ...  ...  ...       ...       ...   \n",
       "12699  12699  0.000000  0.000000  0.0  0.0  0.0  0.0  0.000000  0.000000   \n",
       "12700  12700  0.000000  0.000000  0.0  0.0  0.0  0.0  0.000000  0.000000   \n",
       "12701  12701  0.000000  0.000000  0.0  0.0  0.0  0.0  0.000000  0.000000   \n",
       "12702  12702  0.474252  0.256943  0.0  0.0  0.0  0.0  0.000000  0.000000   \n",
       "12703  12703  0.000000  0.000000  0.0  0.0  0.0  0.0  0.000000  0.000000   \n",
       "\n",
       "            h08  ...       h15       h16       h17       h18       h19  \\\n",
       "0      0.000000  ...  0.156741  0.132883  0.347754  0.522437  0.940441   \n",
       "1      0.000000  ...  0.396663  0.482997  0.320058  0.212006  0.212006   \n",
       "2      0.000000  ...  0.854669  0.991342  0.805263  0.483633  0.000000   \n",
       "3      0.519247  ...  0.551867  0.728864  0.986970  0.917125  0.562874   \n",
       "4      0.172893  ...  0.372387  0.625273  0.878997  0.994609  0.901742   \n",
       "...         ...  ...       ...       ...       ...       ...       ...   \n",
       "12699  0.000000  ...  0.345968  0.228686  0.430487  0.759348  0.991525   \n",
       "12700  0.000000  ...  0.000000  0.000000  0.192508  0.564814  0.973335   \n",
       "12701  0.000000  ...  0.381766  0.381766  0.571624  0.201609  0.144007   \n",
       "12702  0.000000  ...  0.081856  0.174295  0.341396  0.630530  0.810973   \n",
       "12703  0.000000  ...  0.252949  0.277011  0.341672  0.531967  0.812802   \n",
       "\n",
       "            h20       h21       h22       h23  category  \n",
       "0      0.823425  0.000000  0.000000  0.000000         0  \n",
       "1      0.212006  0.000000  0.000000  0.000000         0  \n",
       "2      0.000000  0.000000  0.000000  0.000000         0  \n",
       "3      0.378466  0.000000  0.000000  0.000000         0  \n",
       "4      0.667729  0.387283  0.000000  0.000000         0  \n",
       "...         ...       ...       ...       ...       ...  \n",
       "12699  0.870099  0.588773  0.000000  0.000000       144  \n",
       "12700  0.966669  0.548366  0.000000  0.000000       144  \n",
       "12701  0.334674  0.000000  0.000000  0.000000       144  \n",
       "12702  0.971333  1.000000  0.897192  0.743494       144  \n",
       "12703  0.982816  0.000000  0.000000  0.000000       144  \n",
       "\n",
       "[12704 rows x 26 columns]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_timeseries"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
